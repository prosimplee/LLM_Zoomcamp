{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7377b720-efe0-4365-9634-0fd635f9db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98c2295-e9d0-426d-b3b3-d8612d92c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('/Users/dmitrywer/Desktop/my_projects/LLM_Zoomcamp/01-intro/documents.json','r') as file:\n",
    "    docs_raw = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f475aa9-49f9-4ebd-b48b-70b5d2a848f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a2624f-3a36-440e-9cf3-cd3587e82246",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f95ff8-7bf5-4288-aa77-c129c9fe755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x17fddbe30>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd81fcb-1a60-41bd-b155-bedfbe523de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'This is not a FAQ but more of an advice if you want to set up dbt locally, I did it in the following way:\\nI had the postgres instance from week 2 (year 2024) up (the docker-compose)\\nmkdir dbt\\nvi dbt/profiles.yml\\nAnd here I attached this content (only the required fields) and replaced them with the proper values (for instance mine where in the .env file of the folder of week 2 docker stuff)\\ncd dbt && git clone https://github.com/dbt-labs/dbt-starter-project\\nmkdir project && cd project && mv dbt-starter-project/* .\\nMake sure that you align the profile name in profiles.yml with the dbt_project.yml file\\nAdd this line anywhere on the dbt_project.yml file:\\nconfig-version: 2\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres ls\\nIf you have trouble run\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres debug',\n",
       "  'section': 'Project',\n",
       "  'question': 'Setting up dbt locally with Docker and Postgres',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Check Docker Compose File:\\nEnsure that your docker-compose.yaml file is correctly configured with the necessary details for the \"control-center\" service. Check the service name, image name, ports, volumes, environment variables, and any other configurations required for the container to start.\\nOn Mac OSX 12.2.1 (Monterey) I could not start the kafka control center. I opened Docker Desktop and saw docker images still running from week 4, which I did not see when I typed “docker ps.” I deleted them in docker desktop and then had no problem starting up the kafka environment.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Could not start docker image “control-center” from the docker-compose.yaml file.',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search('Setting up dbt locally with Docker and Postgres?', num_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8283cf39-8d85-4800-8124-e81edd1f706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(question):\n",
    "    boost = {'question' : 3.0, 'section' : 0.5}\n",
    "    results = index.search(query = question, num_results = 3, boost_dict = boost, filter_dict = {'course' : 'data-engineering-zoomcamp'})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27fbc7c-f4c0-47dc-b693-2cb9ab16fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Setting up dbt locally with Docker and Postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c13ee276-4774-458b-99ef-2888480ef9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'This is not a FAQ but more of an advice if you want to set up dbt locally, I did it in the following way:\\nI had the postgres instance from week 2 (year 2024) up (the docker-compose)\\nmkdir dbt\\nvi dbt/profiles.yml\\nAnd here I attached this content (only the required fields) and replaced them with the proper values (for instance mine where in the .env file of the folder of week 2 docker stuff)\\ncd dbt && git clone https://github.com/dbt-labs/dbt-starter-project\\nmkdir project && cd project && mv dbt-starter-project/* .\\nMake sure that you align the profile name in profiles.yml with the dbt_project.yml file\\nAdd this line anywhere on the dbt_project.yml file:\\nconfig-version: 2\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres ls\\nIf you have trouble run\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres debug',\n",
       "  'section': 'Project',\n",
       "  'question': 'Setting up dbt locally with Docker and Postgres',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'The trial dbt account provides access to dbt API. Job will still be needed to be added manually. Airflow will run the job using a python operator calling the API. You will need to provide api key, job id, etc. (be careful not committing it to Github).\\nDetailed explanation here: https://docs.getdbt.com/blog/dbt-airflow-spiritual-alignment\\nSource code example here: https://github.com/sungchun12/airflow-toolkit/blob/95d40ac76122de337e1b1cdc8eed35ba1c3051ed/dags/examples/dbt_cloud_example.py',\n",
       "  'section': 'Project',\n",
       "  'question': 'Orchestrating dbt with Airflow',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'The MacOS setup instruction (https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/05-batch/setup/macos.md#installing-java) for setting the JAVA_HOME environment variable is for Intel-based Macs which have a default install location at /usr/local/. If you have an Apple Silicon mac, you will have to set JAVA_HOME to /opt/homebrew/, specifically in your .bashrc or .zshrc:\\nexport JAVA_HOME=\"/opt/homebrew/opt/openjdk/bin\"\\nexport PATH=\"$JAVA_HOME:$PATH\"\\nConfirm that your path was correctly set by running the command: which java\\nYou should expect to see the output:\\n/opt/homebrew/opt/openjdk/bin/java\\nReference: https://docs.brew.sh/Installation',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Setting JAVA_HOME with Homebrew on Apple Silicon',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76d939b-b9cc-4b28-99d4-689c5a921747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION. If there is no answer, return NONE.\n",
    "    \n",
    "QUESTION: {question}\n",
    "    \n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "    context = ''\n",
    "    for doc in search_results:\n",
    "        context = context + f'section: {doc['section']}\\nquestion: {doc['question']}\\ncontext: {doc['text']}\\n\\n'\n",
    "    return prompt_template.format(question = question, context = context)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae41081e-33da-4947-b29a-21246d87eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    client = OpenAI(\n",
    "        base_url='http://localhost:11434/v1/',\n",
    "        api_key='ollama',\n",
    "        )\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'phi3',\n",
    "        messages = [{'role' : 'user', 'content' : prompt}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a82236-0224-4868-a6e8-47684519b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    result = llm(prompt).strip()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c9f7ae1-23d2-43b3-87b8-93f04fec535e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The project will be evaluated through a peer review process where 3 randomly assigned students who also submitted their projects evaluate your work. Each reviewer should provide feedback in writing based on the reproducibility criterion within two days as mentioned during Zoomcamp Q&A sessions, which is crucial for assessing whether someone can re-run everything or not if it was impossible initially. A follow-up comment will be added to address any difficulties faced due to limited resources like internet access issues; however, in the absence of this resource, trying your best with what you have could suffice as great effort is valued even without perfect reproducibility. The final grade received from these peer reviews should reflect efforts towards ensuring replicability within project work constraints and will be determined by taking into consideration whether such steps were taken or not in the event that complete execution wasn't feasible for a given reviewer, as discussed during Zoomcamp Q&A sessions. This is supplemented with self-grading of 3 fellow students’ projects which also counts towards final evaluation based on their peer reviews; this can affect your ability to achieve course certification if not done accordingly or in compliance to the set rules regarding project submission and passing criteria as highlighted by Zoomcamp instructors.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag('How the project would be evaludated?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8dfbb-7645-4c6a-9347-02013605e8b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
