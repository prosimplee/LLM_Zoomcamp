{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7377b720-efe0-4365-9634-0fd635f9db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98c2295-e9d0-426d-b3b3-d8612d92c09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('/Users/dmitrywer/Desktop/my_projects/LLM_Zoomcamp/documents.json','r') as file:\n",
    "    docs_raw = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f475aa9-49f9-4ebd-b48b-70b5d2a848f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5a2624f-3a36-440e-9cf3-cd3587e82246",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f95ff8-7bf5-4288-aa77-c129c9fe755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x14aa22060>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bd81fcb-1a60-41bd-b155-bedfbe523de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'This is not a FAQ but more of an advice if you want to set up dbt locally, I did it in the following way:\\nI had the postgres instance from week 2 (year 2024) up (the docker-compose)\\nmkdir dbt\\nvi dbt/profiles.yml\\nAnd here I attached this content (only the required fields) and replaced them with the proper values (for instance mine where in the .env file of the folder of week 2 docker stuff)\\ncd dbt && git clone https://github.com/dbt-labs/dbt-starter-project\\nmkdir project && cd project && mv dbt-starter-project/* .\\nMake sure that you align the profile name in profiles.yml with the dbt_project.yml file\\nAdd this line anywhere on the dbt_project.yml file:\\nconfig-version: 2\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres ls\\nIf you have trouble run\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres debug',\n",
       "  'section': 'Project',\n",
       "  'question': 'Setting up dbt locally with Docker and Postgres',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'Check Docker Compose File:\\nEnsure that your docker-compose.yaml file is correctly configured with the necessary details for the \"control-center\" service. Check the service name, image name, ports, volumes, environment variables, and any other configurations required for the container to start.\\nOn Mac OSX 12.2.1 (Monterey) I could not start the kafka control center. I opened Docker Desktop and saw docker images still running from week 4, which I did not see when I typed “docker ps.” I deleted them in docker desktop and then had no problem starting up the kafka environment.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Could not start docker image “control-center” from the docker-compose.yaml file.',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.search('Setting up dbt locally with Docker and Postgres?', num_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8283cf39-8d85-4800-8124-e81edd1f706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(question):\n",
    "    boost = {'question' : 3.0, 'section' : 0.5}\n",
    "    results = index.search(query = question, num_results = 3, boost_dict = boost, filter_dict = {'course' : 'data-engineering-zoomcamp'})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f27fbc7c-f4c0-47dc-b693-2cb9ab16fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Setting up dbt locally with Docker and Postgres'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c13ee276-4774-458b-99ef-2888480ef9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'This is not a FAQ but more of an advice if you want to set up dbt locally, I did it in the following way:\\nI had the postgres instance from week 2 (year 2024) up (the docker-compose)\\nmkdir dbt\\nvi dbt/profiles.yml\\nAnd here I attached this content (only the required fields) and replaced them with the proper values (for instance mine where in the .env file of the folder of week 2 docker stuff)\\ncd dbt && git clone https://github.com/dbt-labs/dbt-starter-project\\nmkdir project && cd project && mv dbt-starter-project/* .\\nMake sure that you align the profile name in profiles.yml with the dbt_project.yml file\\nAdd this line anywhere on the dbt_project.yml file:\\nconfig-version: 2\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres ls\\nIf you have trouble run\\ndocker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres debug',\n",
       "  'section': 'Project',\n",
       "  'question': 'Setting up dbt locally with Docker and Postgres',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'The trial dbt account provides access to dbt API. Job will still be needed to be added manually. Airflow will run the job using a python operator calling the API. You will need to provide api key, job id, etc. (be careful not committing it to Github).\\nDetailed explanation here: https://docs.getdbt.com/blog/dbt-airflow-spiritual-alignment\\nSource code example here: https://github.com/sungchun12/airflow-toolkit/blob/95d40ac76122de337e1b1cdc8eed35ba1c3051ed/dags/examples/dbt_cloud_example.py',\n",
       "  'section': 'Project',\n",
       "  'question': 'Orchestrating dbt with Airflow',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'The MacOS setup instruction (https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/05-batch/setup/macos.md#installing-java) for setting the JAVA_HOME environment variable is for Intel-based Macs which have a default install location at /usr/local/. If you have an Apple Silicon mac, you will have to set JAVA_HOME to /opt/homebrew/, specifically in your .bashrc or .zshrc:\\nexport JAVA_HOME=\"/opt/homebrew/opt/openjdk/bin\"\\nexport PATH=\"$JAVA_HOME:$PATH\"\\nConfirm that your path was correctly set by running the command: which java\\nYou should expect to see the output:\\n/opt/homebrew/opt/openjdk/bin/java\\nReference: https://docs.brew.sh/Installation',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Setting JAVA_HOME with Homebrew on Apple Silicon',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76d939b-b9cc-4b28-99d4-689c5a921747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(question, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION. If there is no answer, return NONE.\n",
    "    \n",
    "QUESTION: {question}\n",
    "    \n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "    context = ''\n",
    "    for doc in search_results:\n",
    "        context = context + f'section: {doc['section']}\\nquestion: {doc['question']}\\ncontext: {doc['text']}\\n\\n'\n",
    "    return prompt_template.format(question = question, context = context)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c53198f-408f-4e4f-b048-f90d91204403",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Setting up dbt locally with Docker and Postgres?'\n",
    "search_results = search(question)\n",
    "prompt = build_prompt(question, search_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea783fbb-5fb4-498e-aa3a-17178023f190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
      "Use only the facts from the CONTEXT when answering the QUESTION. If there is no answer, return NONE.\n",
      "    \n",
      "QUESTION: Setting up dbt locally with Docker and Postgres?\n",
      "    \n",
      "CONTEXT: \n",
      "section: Project\n",
      "question: Setting up dbt locally with Docker and Postgres\n",
      "context: This is not a FAQ but more of an advice if you want to set up dbt locally, I did it in the following way:\n",
      "I had the postgres instance from week 2 (year 2024) up (the docker-compose)\n",
      "mkdir dbt\n",
      "vi dbt/profiles.yml\n",
      "And here I attached this content (only the required fields) and replaced them with the proper values (for instance mine where in the .env file of the folder of week 2 docker stuff)\n",
      "cd dbt && git clone https://github.com/dbt-labs/dbt-starter-project\n",
      "mkdir project && cd project && mv dbt-starter-project/* .\n",
      "Make sure that you align the profile name in profiles.yml with the dbt_project.yml file\n",
      "Add this line anywhere on the dbt_project.yml file:\n",
      "config-version: 2\n",
      "docker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres ls\n",
      "If you have trouble run\n",
      "docker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres debug\n",
      "\n",
      "section: Project\n",
      "question: Orchestrating dbt with Airflow\n",
      "context: The trial dbt account provides access to dbt API. Job will still be needed to be added manually. Airflow will run the job using a python operator calling the API. You will need to provide api key, job id, etc. (be careful not committing it to Github).\n",
      "Detailed explanation here: https://docs.getdbt.com/blog/dbt-airflow-spiritual-alignment\n",
      "Source code example here: https://github.com/sungchun12/airflow-toolkit/blob/95d40ac76122de337e1b1cdc8eed35ba1c3051ed/dags/examples/dbt_cloud_example.py\n",
      "\n",
      "section: Module 6: streaming with kafka\n",
      "question: Setting JAVA_HOME with Homebrew on Apple Silicon\n",
      "context: The MacOS setup instruction (https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/05-batch/setup/macos.md#installing-java) for setting the JAVA_HOME environment variable is for Intel-based Macs which have a default install location at /usr/local/. If you have an Apple Silicon mac, you will have to set JAVA_HOME to /opt/homebrew/, specifically in your .bashrc or .zshrc:\n",
      "export JAVA_HOME=\"/opt/homebrew/opt/openjdk/bin\"\n",
      "export PATH=\"$JAVA_HOME:$PATH\"\n",
      "Confirm that your path was correctly set by running the command: which java\n",
      "You should expect to see the output:\n",
      "/opt/homebrew/opt/openjdk/bin/java\n",
      "Reference: https://docs.brew.sh/Installation\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae41081e-33da-4947-b29a-21246d87eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm(prompt):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'gpt-4o',\n",
    "        messages = [{'role' : 'user', 'content' : prompt}])\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36a82236-0224-4868-a6e8-47684519b701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If you want to set up dbt locally with Docker and Postgres, here is a recommended step-by-step approach:\\n\\n1. **Run Postgres Instance:**\\n   - Ensure you have the Postgres instance from week 2 (year 2024) up and running using Docker Compose.\\n\\n2. **Set Up Directories:**\\n   - Create a directory for dbt:\\n     ```sh\\n     mkdir dbt\\n     ```\\n\\n3. **Create profiles.yml:**\\n   - Use a text editor to create `profiles.yml` within the `dbt` directory. Fill in the required fields and replace placeholder values with those appropriate for your setup (for instance, from the `.env` file of the week 2 Docker setup).\\n\\n4. **Clone the dbt Starter Project:**\\n   - Navigate to the `dbt` directory and clone the dbt starter project:\\n     ```sh\\n     cd dbt\\n     git clone https://github.com/dbt-labs/dbt-starter-project\\n     ```\\n\\n5. **Set Up the dbt Project:**\\n   - Create a project directory and move the starter project files:\\n     ```sh\\n     mkdir project\\n     cd project\\n     mv dbt-starter-project/* .\\n     ```\\n\\n6. **Ensure Configuration Consistency:**\\n   - Make sure to align the profile name in `profiles.yml` with the `dbt_project.yml` file.\\n\\n7. **Add Configuration Version:**\\n   - Add the following line to the `dbt_project.yml` file:\\n     ```yaml\\n     config-version: 2\\n     ```\\n\\n8. **Run dbt with Docker:**\\n   - Execute the following command to run dbt using Docker, ensuring to replace `/<your-path>` with the relevant path:\\n     ```sh\\n     docker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres ls\\n     ```\\n\\n9. **Debugging:**\\n   - If you encounter issues, you can run the debug command:\\n     ```sh\\n     docker run --network=mage-zoomcamp_default --mount type=bind,source=/<your-path>/dbt/project,target=/usr/app --mount type=bind,source=/<your-path>/profiles.yml,target=/root/.dbt/profiles.yml ghcr.io/dbt-labs/dbt-postgres debug\\n     ```\\n\\nThis should help you set up dbt locally with Docker and Postgres effectively.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f7ae1-23d2-43b3-87b8-93f04fec535e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
