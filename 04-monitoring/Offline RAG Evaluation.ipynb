{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fec5544-b41a-48ee-ba9f-ec8c38f1b8ef",
   "metadata": {},
   "source": [
    "## Load the documents with ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "56f3bf23-3669-401a-80f8-0ace4dda4791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open ('documents-with-ids.json', 'r') as file:\n",
    "    documents = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "41d513e7-8d3e-42f4-ac57-3c3763cb1165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - \\u200b\\u200bHow many hours per week am I expected to spend on this  course?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'ea739c65'}"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eafe29-d8bf-4776-bb49-7451062f067f",
   "metadata": {},
   "source": [
    "## Load groud truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "adee7e90-67ba-489b-92cc-5fda60a2ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "with open ('ground-truth-data.csv', 'r') as g_file:\n",
    "    ground_truth_df = pd.read_csv(g_file)\n",
    "    ground_truth_df = ground_truth_df[ground_truth_df['course'] == 'machine-learning-zoomcamp']\n",
    "    ground_truth = ground_truth_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d7cc867c-7c87-465f-ab63-2073ea94631d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Are sessions recorded if I miss one?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '5170565b'}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e23367-b236-454d-8b9b-a9d4cc2763e3",
   "metadata": {},
   "source": [
    "## To quickly retrieve the documents let's assign id directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "57655809-2ea9-4304-b659-f134856f2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_id = {d['id'] : d for d in documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1b68a577-2188-4bbe-8812-a0ef5f8de996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It depends on your background and previous experience with modules. It is expected to require about 5 - 15 hours per week. [source1] [source2]\\nYou can also calculate it yourself using this data and then update this answer.'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id['ea739c65']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c6aaa5-b103-4fee-a52b-c326a45b48c7",
   "metadata": {},
   "source": [
    "## Let's index the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4d48500f-c39c-45cc-bd81-29a25345ab57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1b24989e-97ac-458b-8b69-17159890a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "88c7678a-0892-4412-8163-fb04fa1ed16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "74697b5c-7ed1-4e4d-97e9-a77451d8adb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ecc417c5-ff99-40fb-a595-0be7050a0950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "669a7739-b549-42c1-9546-ae739b081fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    \n",
    "    doc['question_text_vector'] = model.encode(question + ' ' + text)\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb2cb8-fd66-461f-99f4-45bd7f554974",
   "metadata": {},
   "source": [
    "## Retrieve the documents based on our query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e637f9ff-f961-49a1-a9c8-3d4c3fa34dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "6ee4d1e7-56c7-430b-8746-8bd0f8c9e51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_text_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "c1a8a533-a56d-4b56-be8c-7133d0603bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What if I miss a session?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'id': '5170565b'},\n",
       " {'question': 'Is it going to be live? When?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'id': '39fda9f0'},\n",
       " {'question': 'The same accuracy on epochs',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': '8. Neural Networks and Deep Learning',\n",
       "  'text': \"Problem description\\nThe accuracy and the loss are both still the same or nearly the same while training.\\nSolution description\\nIn the homework, you should set class_mode='binary' while reading the data.\\nAlso, problem occurs when you choose the wrong optimizer, batch size, or learning rate\\nAdded by Ekaterina Kutovaia\",\n",
       "  'id': '7d11d5ce'},\n",
       " {'question': 'Useful Resource for Missing Data Treatment\\nhttps://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python/notebook',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': '2. Machine Learning for Regression',\n",
       "  'text': '(Hrithik Kumar Advani)',\n",
       "  'id': '81b8e8d0'},\n",
       " {'question': 'Will I get a certificate if I missed the midterm project?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'section': 'General course-related questions',\n",
       "  'text': \"Yes, it's possible. See the previous answer.\",\n",
       "  'id': '1d644223'}]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_text_vector_knn(dict(\n",
    "    question='Are sessions recorded if I miss one?',\n",
    "    course='machine-learning-zoomcamp'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f956e63b-8063-46d6-9a99-8463a044e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "acda8f0b-0b69-43e2-8ba5-99d4e6afb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4o-mini'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b0d78c1e-b6c6-40bc-916b-a96cf5884d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously: rag(query: str) -> str\n",
    "def rag(query: dict) -> str:\n",
    "    search_results = question_text_vector_knn(query)\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "990b1bdc-5999-4fa4-a218-a734d83443de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, sessions are recorded, so if you miss one, you won’t miss anything. You can catch up on the recorded material, and you can also ask questions in advance for office hours, which will be covered during the live stream.'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(dict(\n",
    "    question='Are sessions recorded if I miss one?',\n",
    "    course='machine-learning-zoomcamp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96701256-b5b8-42df-a684-fdb3c6039780",
   "metadata": {},
   "source": [
    "## Test with questions which were generated by LLM in prev lessons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "78be7a41-2300-42e1-bd39-e16143417b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Can you provide a link to sign up?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '0227b872'}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "57c2ffd0-b84e-4dcf-9199-f3f28e0b0d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can sign up using the link in the course GitHub repository: [Sign Up Here](https://airtable.com/shryxwLd0COOEaqXo).\n"
     ]
    }
   ],
   "source": [
    "print(rag(ground_truth[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "f129401d-fd63-4dc7-a5e4-57f1dcb8760a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\""
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_id['c02e79ef']['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff7a88a-573d-4089-bee9-50a15341d56c",
   "metadata": {},
   "source": [
    "## Cosine Similarity Metric to check how similar they are (1 question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "7587f9e3-f1d5-4535-b7e1-6ba4b30b2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response = \"\"\"To receive course announcements, join the course Telegram channel with announcements and register in DataTalks.Club's Slack and join the channel\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6a9f5151-c1f7-4836-ab4b-61ca01ad74a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_response_v = model.encode(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6891a75a-6b11-48d7-a868-f04d0eef36ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_response = doc_id['c02e79ef']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "80f2727b-f4ac-47aa-bdb6-c1f66057864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_response_v = model.encode(real_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f941a4b5-7676-4403-91c8-9c72e27abd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7277642"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response_v.dot(real_response_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985a27fd-ebd1-44eb-ac71-3016c4e71d81",
   "metadata": {},
   "source": [
    "## Cosine Similarity Metric to check how similar they are (all questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fab40c42-67ce-446a-b595-6547fb61e113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Are sessions recorded if I miss one?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '5170565b'}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "08f12b61-75f1-4ebf-ada8-12ecfa8f932a",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "2025a60f-eb6c-45b7-88d9-86d39a1cb870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "for i, record in enumerate(ground_truth):\n",
    "    if i in answers:\n",
    "        continue\n",
    "    \n",
    "    llm_answer = rag(record)\n",
    "\n",
    "    document = doc_id[record['document']]\n",
    "    real_answer = document['text']\n",
    "\n",
    "    answers[i] = {\n",
    "        'answer_llm': llm_answer,\n",
    "        'real_answer': real_answer,\n",
    "        'document_id': document['id'],\n",
    "        'question': record['question'],\n",
    "        'course': document['course']\n",
    "    }\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "687cebb2-3eb1-41b7-bd93-b7a3c21cba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1830"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "95656c3c-a29a-456e-8093-f94ee7bb3f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'You can sign up for the course by going to the course page at http://mlzoomcamp.com/.',\n",
       " 'real_answer': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'document_id': '0227b872',\n",
       " 'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "2bd44fb7-f0f4-4151-a706-6becd6264b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4_o = pd.DataFrame(answers.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "3c63a10b-41b4-4150-9225-bde991e9239f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'Values tend to be close to the mean if they have a low standard deviation.',\n",
       " 'real_answer': 'In statistics, the standard deviation is a measure of the amount of variation or dispersion of a set of values. A low standard deviation indicates that the values tend to be close to the mean (also called the expected value) of the set, while a high standard deviation indicates that the values are spread out over a wider range. [Wikipedia] The formula to calculate standard deviation is:\\n(Aadarsha Shrestha)',\n",
       " 'document_id': '266faa6d',\n",
       " 'question': 'Where do values tend to be if they have a low standard deviation?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4_o.sample(n = 5).to_dict(orient = 'records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "753a9316-f599-4ebc-b388-34c93ceb1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4_o.to_csv('results_df_gpt4_oturbo.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ffee1-5a18-41e5-a0fe-84fad5322046",
   "metadata": {},
   "source": [
    "## Compute Cosine Similarity\n",
    "\n",
    "A - original answer;\n",
    "Q - synthetically generated question;\n",
    "A'- answer from the LLM\n",
    "\n",
    "Cosine Similarity (A, and A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "2f738099-c8b8-45be-bfc8-c6fddff6b26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>real_answer</th>\n",
       "      <th>document_id</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by going to the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up by visiting the course GitHub ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by going to the...   \n",
       "1  You can sign up by visiting the course GitHub ...   \n",
       "\n",
       "                                         real_answer document_id  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...    0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...    0227b872   \n",
       "\n",
       "                              question                     course  \n",
       "0  Where can I sign up for the course?  machine-learning-zoomcamp  \n",
       "1   Can you provide a link to sign up?  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv('results_df_gpt4_oturbo.csv')[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "2c04d5c7-7c75-4c81-8f05-075a25d0a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_df_gpt4_oturbo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b68dd5e4-7abe-4c9a-9a59-e406241f5a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['answer_llm'] != 'NONE') & (df['course'] == 'machine-learning-zoomcamp')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "df1994d4-0ef5-4e33-9b78-55fbe9a92965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['machine-learning-zoomcamp'], dtype=object)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['course'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e6922adb-9ef2-4037-ada5-556e9487255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4_o = df.to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c3b3e908-4579-412a-9195-93f6a253b40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'You can sign up for the course by going to the course page at http://mlzoomcamp.com/.',\n",
       " 'real_answer': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'document_id': '0227b872',\n",
       " 'question': 'Where can I sign up for the course?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gpt4_o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b2b91f27-dc56-43e7-954b-87c82bba0e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "def cosine_similarity(record):\n",
    "    llm_ans = model.encode(record['answer_llm'])\n",
    "    real_ans = model.encode(record['real_answer'])\n",
    "    cos = llm_ans.dot(real_ans)\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "37779858-741f-4fba-a3ab-b6a0117ce73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for rec in results_gpt4_o:\n",
    "    if cosine_similarity is not None: \n",
    "        results.append(cosine_similarity(rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "d65d75d8-286e-4383-a6cf-1b6227d4c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cosine_sim'] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "d37f4ddd-bb61-4262-bce2-dcbb537d8071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>real_answer</th>\n",
       "      <th>document_id</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "      <th>cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You can sign up for the course by going to the...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.416958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up by visiting the course GitHub ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.368035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.710604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Based on the provided context, there is no men...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>-0.032536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.408523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The course videos are pre-recorded, so you can...</td>\n",
       "      <td>The course videos are pre-recorded, you can st...</td>\n",
       "      <td>39fda9f0</td>\n",
       "      <td>Are the course videos live or pre-recorded?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.763997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You can start watching the course videos right...</td>\n",
       "      <td>The course videos are pre-recorded, you can st...</td>\n",
       "      <td>39fda9f0</td>\n",
       "      <td>When can I start watching the course videos?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.778924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yes, the live office hours sessions are recorded.</td>\n",
       "      <td>The course videos are pre-recorded, you can st...</td>\n",
       "      <td>39fda9f0</td>\n",
       "      <td>Are the live office hours sessions recorded?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.571757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You can find the office hours sessions recorde...</td>\n",
       "      <td>The course videos are pre-recorded, you can st...</td>\n",
       "      <td>39fda9f0</td>\n",
       "      <td>Where can I find the office hours sessions?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.761989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>You can access the pre-recorded course videos ...</td>\n",
       "      <td>The course videos are pre-recorded, you can st...</td>\n",
       "      <td>39fda9f0</td>\n",
       "      <td>Where can I access the pre-recorded course vid...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "      <td>0.694365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  You can sign up for the course by going to the...   \n",
       "1  You can sign up by visiting the course GitHub ...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  Based on the provided context, there is no men...   \n",
       "4  To structure your questions and answers for th...   \n",
       "5  The course videos are pre-recorded, so you can...   \n",
       "6  You can start watching the course videos right...   \n",
       "7  Yes, the live office hours sessions are recorded.   \n",
       "8  You can find the office hours sessions recorde...   \n",
       "9  You can access the pre-recorded course videos ...   \n",
       "\n",
       "                                         real_answer document_id  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...    0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...    0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...    0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...    0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...    0227b872   \n",
       "5  The course videos are pre-recorded, you can st...    39fda9f0   \n",
       "6  The course videos are pre-recorded, you can st...    39fda9f0   \n",
       "7  The course videos are pre-recorded, you can st...    39fda9f0   \n",
       "8  The course videos are pre-recorded, you can st...    39fda9f0   \n",
       "9  The course videos are pre-recorded, you can st...    39fda9f0   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "5        Are the course videos live or pre-recorded?   \n",
       "6       When can I start watching the course videos?   \n",
       "7       Are the live office hours sessions recorded?   \n",
       "8        Where can I find the office hours sessions?   \n",
       "9  Where can I access the pre-recorded course vid...   \n",
       "\n",
       "                      course  cosine_sim  \n",
       "0  machine-learning-zoomcamp    0.416958  \n",
       "1  machine-learning-zoomcamp    0.368035  \n",
       "2  machine-learning-zoomcamp    0.710604  \n",
       "3  machine-learning-zoomcamp   -0.032536  \n",
       "4  machine-learning-zoomcamp    0.408523  \n",
       "5  machine-learning-zoomcamp    0.763997  \n",
       "6  machine-learning-zoomcamp    0.778924  \n",
       "7  machine-learning-zoomcamp    0.571757  \n",
       "8  machine-learning-zoomcamp    0.761989  \n",
       "9  machine-learning-zoomcamp    0.694365  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "59002194-2713-4a1b-878c-39b25fa0e774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1830.000000\n",
       "mean        0.680557\n",
       "std         0.217157\n",
       "min        -0.147974\n",
       "25%         0.591140\n",
       "50%         0.735822\n",
       "75%         0.835435\n",
       "max         0.987929\n",
       "Name: cosine_sim, dtype: float64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cosine_sim'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10cbb9e-f6dd-45b6-8e50-a19e3675aa7a",
   "metadata": {},
   "source": [
    "## Offline RAG Eval- LLM as a Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "6037d22e-b539-4610-ae4a-689f4f4170d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_eval = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {real_answer}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "430f8567-d4d5-42ec-bde9-b9e19735d216",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(n = 100, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "13e3c3e6-7062-4ea4-9928-cd827f8d11e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = df_sample.to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2af2f4b4-bcc7-4c6c-96c2-eacf87a40ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "record_test = df_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "f3fdc5e9-59df-44b3-962d-1aaebf160e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'The syntax for using `precision_recall_fscore_support` in Python is as follows:\\n\\n```python\\nfrom sklearn.metrics import precision_recall_fscore_support\\nprecision, recall, fscore, support = precision_recall_fscore_support(y_val, y_val_pred, zero_division=0)\\n```',\n",
       " 'real_answer': 'Scikit-learn offers another way: precision_recall_fscore_support\\nExample:\\nfrom sklearn.metrics import precision_recall_fscore_support\\nprecision, recall, fscore, support = precision_recall_fscore_support(y_val, y_val_pred, zero_division=0)\\n(Gopakumar Gopinathan)',\n",
       " 'document_id': '403bbdd8',\n",
       " 'question': 'What is the syntax for using precision_recall_fscore_support in Python?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'cosine_sim': 0.9010754823684692}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "dd41c632-cde2-4eef-b0c9-a531af3377cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: Scikit-learn offers another way: precision_recall_fscore_support\n",
      "Example:\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "precision, recall, fscore, support = precision_recall_fscore_support(y_val, y_val_pred, zero_division=0)\n",
      "(Gopakumar Gopinathan)\n",
      "Generated Question: What is the syntax for using precision_recall_fscore_support in Python?\n",
      "Generated Answer: The syntax for using `precision_recall_fscore_support` in Python is as follows:\n",
      "\n",
      "```python\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "precision, recall, fscore, support = precision_recall_fscore_support(y_val, y_val_pred, zero_division=0)\n",
      "```\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template_eval.format(**record_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ea3e6539-3e3a-4c37-95ac-57d0997d10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template_eval.format(**record_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "81993b95-eed3-461b-8683-45c79e2bf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_answer = llm(prompt_template_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9293df13-b876-4540-b152-6d0a8ffc4361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "bcdd7be7-6ea3-43fa-9b5e-a45934f2db14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Relevance': 'RELEVANT',\n",
       " 'Explanation': 'The generated answer closely aligns with the original answer by accurately capturing the essential points and context provided in the real answer.'}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(test_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "de1b4199-7527-427b-ac7d-14bb05b2d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test = []\n",
    "for rec in df_dict:\n",
    "    prompt = prompt_template_eval.format(**rec)\n",
    "    evaluation = llm(prompt)\n",
    "    results_test.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f2751e7f-0cbb-4bcf-ac8d-f7a01f4232f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "88465606-3d65-49d7-901b-9484b3553673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON at index 82: Expecting property name enclosed in double quotes: line 4 column 1 (char 317)\n"
     ]
    }
   ],
   "source": [
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(results_test):\n",
    "    try:\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "bda0cce4-5d9e-4437-a855-31b973795969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "81d98016-5048-4079-8fa9-a01316ac1ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evals = pd.DataFrame(json_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "9173b10a-2aa3-4bae-a03d-926f4483d9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           78\n",
       "PARTLY_RELEVANT    15\n",
       "NON_RELEVANT        6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evals['Relevance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "47547971-4754-431e-95d5-4fe07ad55d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a different iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a different iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a different que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer indicates that it cannot ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a different que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not relate to the or...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Relevance                                        Explanation\n",
       "4   NON_RELEVANT  The generated answer addresses a different iss...\n",
       "11  NON_RELEVANT  The generated answer addresses a different iss...\n",
       "41  NON_RELEVANT  The generated answer addresses a different que...\n",
       "45  NON_RELEVANT  The generated answer indicates that it cannot ...\n",
       "89  NON_RELEVANT  The generated answer addresses a different que...\n",
       "92  NON_RELEVANT  The generated answer does not relate to the or..."
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evals[df_evals['Relevance'] == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "5de8b40a-1dd5-42a0-a4a7-bdd16e7b5aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': \"The cause of the pip version error in this week's serverless deep learning section may be due to version conflicts, particularly related to the Scikit-Learn version. If the version of Scikit-Learn used for training the model differs from the version used in the virtual environment, it can lead to issues. For example, ensuring that the model and DictVectorizer files were created with the same Scikit-Learn version you are using for the project is crucial to avoid such errors.\",\n",
       " 'real_answer': 'When running docker build -t dino-dragon-model it returns the above error\\nThe most common source of this error in this week is because Alex video shows a version of the wheel with python 8, we need to find a wheel with the version that we are working on. In this case python 9. Another common error is to copy the link, this will also produce the same error, we need to download the raw format:\\nhttps://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.7.0-cp39-cp39-linux_x86_64.whl\\nPastor Soto',\n",
       " 'document_id': '42c09143',\n",
       " 'question': \"What might be the cause of the pip version error in this week's serverless deep learning section?\",\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'cosine_sim': 0.29866498708724976}"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fba6957-c876-49df-bbae-b2f7fb2a10d5",
   "metadata": {},
   "source": [
    "## Another Evaluation metric (as a judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "4831508f-edc6-4071-addb-eb9d7c28592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_analyze = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f50eb17f-c1c9-433e-9fd7-623920e99448",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template_analyze.format(**df_dict[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "a75d6e90-1067-4636-b482-08e1b176236f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: How should I modify my scripts to avoid pickle errors when using waitress?\n",
      "Generated Answer: To avoid pickle errors when using waitress, you should modify your scripts by putting the custom column transformer class into a separate module. Import this module in both the script that saves the model (e.g., train.py) and the script that loads the model (e.g., predict.py). This is necessary because when the model is saved, it references the class in the global namespace (__main__). When using waitress, it tries to load the class from the global namespace of the predict_app module, leading to a pickle error if the class cannot be found.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0ab30f5e-8d53-4196-8814-5f9210df4ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "\n",
    "for record in df_dict:\n",
    "    prompt = prompt_template_analyze.format(**record)\n",
    "    evaluation = llm(prompt)\n",
    "    evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "6a2b6f14-70ca-4466-9e4d-bcae9449f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations):\n",
    "    try:\n",
    "        json_eval = json.loads(str_eval)\n",
    "        json_evaluations.append(json_eval)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON at index {i}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "ba4f8788-3eb5-4428-ab84-438c10ed14eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_metric = pd.DataFrame(json_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "8746b5c3-63bc-4a13-96dc-230fc320a3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer accurately provides the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>PARTLY_RELEVANT</td>\n",
       "      <td>The generated answer includes some of the step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RELEVANT</td>\n",
       "      <td>The generated answer directly addresses the qu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Relevance                                        Explanation\n",
       "0          RELEVANT  The generated answer directly addresses the qu...\n",
       "1          RELEVANT  The generated answer directly addresses the qu...\n",
       "2          RELEVANT  The generated answer accurately provides the c...\n",
       "3          RELEVANT  The generated answer directly addresses the qu...\n",
       "4          RELEVANT  The generated answer directly addresses the pi...\n",
       "..              ...                                                ...\n",
       "95  PARTLY_RELEVANT  The generated answer includes some of the step...\n",
       "96         RELEVANT  The generated answer directly addresses the qu...\n",
       "97         RELEVANT  The generated answer directly addresses the qu...\n",
       "98         RELEVANT  The generated answer directly addresses the qu...\n",
       "99         RELEVANT  The generated answer directly addresses the qu...\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b12b9302-10e6-4c9b-a079-173baf4ccb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           85\n",
       "PARTLY_RELEVANT    13\n",
       "NON_RELEVANT        2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_metric['Relevance'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "50a87e55-d06a-4240-ac1d-c1a34c3e5de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer indicates that there is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the ques...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Relevance                                        Explanation\n",
       "45  NON_RELEVANT  The generated answer indicates that there is n...\n",
       "49  NON_RELEVANT  The generated answer does not address the ques..."
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval_metric[df_eval_metric['Relevance'] == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "bba03f98-c7c0-4079-bf61-5a1b8f2c1058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'The provided CONTEXT does not contain information regarding commands to start the Docker daemon on Linux. Therefore, I cannot answer the QUESTION based on the given CONTEXT.',\n",
       " 'real_answer': 'Working on getting Docker installed - when I try running hello-world I am getting the error.\\nDocker: Cannot connect to the docker daemon at unix:///var/run/docker.sock. Is the Docker daemon running ?\\nSolution description\\nIf you’re getting this error on WSL, re-install your docker: remove the docker installation from WSL and install Docker Desktop on your host machine (Windows).\\nOn Linux, start the docker daemon with either of these commands:\\nsudo dockerd\\nsudo service docker start\\nAdded by Ugochukwu Onyebuchi',\n",
       " 'document_id': '4b2a3181',\n",
       " 'question': 'What commands should I use to start the docker daemon on Linux?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'cosine_sim': 0.4448443055152893}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "7db035fc-73ac-4471-b070-543e66c4ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'Based on the context provided, there is no mention of a YouTube video covering Evaluation Metrics for Classification. The information primarily relates to methods and techniques using tools like scikit-learn and Yellowbrick for computing and visualizing classification metrics.',\n",
       " 'real_answer': 'Week 4 HW: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/04-evaluation/homework.md\\nAll HWs: https://github.com/DataTalksClub/machine-learning-zoomcamp/blob/master/cohorts/2023/\\nEvaluation Matrix: https://docs.google.com/spreadsheets/d/e/2PACX-1vQCwqAtkjl07MTW-SxWUK9GUvMQ3Pv_fF8UadcuIYLgHa0PlNu9BRWtfLgivI8xSCncQs82HDwGXSm3/pubhtml\\nGitHub for theory: https://github.com/alexeygrigorev/mlbookcamp-code/tree/master/course-zoomcamp\\nYouTube Link: 4.X --- https://www.youtube.com/watch?v=gmg5jw1bM8A&list=PL3MmuxUbc_hIhxl5Ji8t4O6lPAOpHaCLR&index=40\\nSci-Kit Learn on Evaluation:\\nhttps://scikit-learn.org/stable/model_selection.html\\n~~Nukta Bhatia~~',\n",
       " 'document_id': '27c8d5da',\n",
       " 'question': 'Do you have a YouTube video covering Evaluation Metrics for Classification?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'cosine_sim': 0.35739636421203613}"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfdc4e3-8bf2-4eb0-93ff-28793ec0086f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
